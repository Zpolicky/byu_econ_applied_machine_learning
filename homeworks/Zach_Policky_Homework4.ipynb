{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surviving the Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using data about the passengers aboard the Titanic, I will use machine learning to predict if a passenger survived or not. To accomplish this I will first clean the data, feature engineer new variables, then train a model and use it to predict survival.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the train and test sets from kaggle\n",
    "train = pd.read_csv(\"C:/Users/zachp/Downloads/train_titanic.csv\")\n",
    "test = pd.read_csv(\"C:/Users/zachp/Downloads/test_titanic.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived      Pclass         Age       SibSp       Parch        Fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make the PassengerId variable the index variable\n",
    "train.set_index('PassengerId', inplace = True)\n",
    "test.set_index('PassengerId', inplace = True)\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the data, I know that age has missing values so before I can run any preliminary models I need to fill in the values for age. I will fill the missing values with the average age of the training data on both the train and test data sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Age'] = train['Age'].fillna(train.Age.mean())\n",
    "test['Age'] = test['Age'].fillna(train.Age.mean())\n",
    "#check to make sure there are 891 observations of age in the training data\n",
    "train['Age'].count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now split into training and test set\n",
    "target = train['Survived']\n",
    "train = train.drop('Survived', axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data is cleaned and split into a train and test data set I can build a basic model. Even though this is early in the process I want train and test a model so I can see how much additional cleaning I will need to do. I can also see the effect of cleaning, scaling, and feature engineering by comparing new models to this original model. For this model, I will ignore all object variables and just use the orignial numeric variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>596.000000</td>\n",
       "      <td>596.000000</td>\n",
       "      <td>596.000000</td>\n",
       "      <td>596.000000</td>\n",
       "      <td>596.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.337248</td>\n",
       "      <td>29.560262</td>\n",
       "      <td>0.577181</td>\n",
       "      <td>0.374161</td>\n",
       "      <td>31.912786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.823207</td>\n",
       "      <td>12.944885</td>\n",
       "      <td>1.229504</td>\n",
       "      <td>0.807072</td>\n",
       "      <td>51.480961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Pclass         Age       SibSp       Parch        Fare\n",
       "count  596.000000  596.000000  596.000000  596.000000  596.000000\n",
       "mean     2.337248   29.560262    0.577181    0.374161   31.912786\n",
       "std      0.823207   12.944885    1.229504    0.807072   51.480961\n",
       "min      1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      2.000000   22.000000    0.000000    0.000000    7.925000\n",
       "50%      3.000000   29.699118    0.000000    0.000000   14.454200\n",
       "75%      3.000000   35.000000    1.000000    0.000000   31.275000\n",
       "max      3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_variables = list(X_train.dtypes[X_train.dtypes!= 'object'].index)\n",
    "X_train[numeric_variables].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests train a bunch of decision trees that are all different and then combine them via voting. Basically, you take the most common predicted class as the prediction (hard voting) and you can get probabilities by taking the fraction (soft voting). It is fairly easy to see how multiple models might be more effective than a single model if they all look at the data in a different way. Random Forest assumes taht group thinking is the same as an expert opinion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 5 balanced\n",
      "5000 5 None\n"
     ]
    }
   ],
   "source": [
    "#now I will use a for loop to determine what the best parameters are. \n",
    "\n",
    "\n",
    "n_estimators = [5000]\n",
    "max_depth = [5]\n",
    "class_weights = ['balanced', None]\n",
    "best_f1 = 0\n",
    "\n",
    "for est in n_estimators:\n",
    "    for depth in max_depth:\n",
    "        for wgt in class_weights:\n",
    "            print(est, depth, wgt)\n",
    "            clf = RandomForestClassifier(n_estimators=est, max_depth=depth, oob_score=True, class_weight=wgt)\n",
    "            clf.fit(X_train[numeric_variables],y_train)\n",
    "            f1 = f1_score(y_train, np.argmax(clf.oob_decision_function_ , 1))\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_params = (est, depth, wgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best OOB F1: 0.5838509316770186\n",
      "Best params: (5000, 5, 'balanced')\n"
     ]
    }
   ],
   "source": [
    "print(\"Best OOB F1: {}\".format(best_f1))\n",
    "print(\"Best params: {}\".format(best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.72      0.76       175\n",
      "          1       0.64      0.73      0.68       120\n",
      "\n",
      "avg / total       0.73      0.73      0.73       295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model1 = RandomForestClassifier(n_estimators=best_params[0], max_depth=best_params[1], class_weight=best_params[2])\n",
    "\n",
    "model1.fit(X_train[numeric_variables],y_train)\n",
    "\n",
    "test_predictions = model1.predict(X_test[numeric_variables])\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first model is ok but not great. I will try some additional cleaning and feature engineering and then make a new model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>596</td>\n",
       "      <td>596</td>\n",
       "      <td>596</td>\n",
       "      <td>134</td>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>596</td>\n",
       "      <td>2</td>\n",
       "      <td>480</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Coleridge, Mr. Reginald Charles</td>\n",
       "      <td>male</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>390</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def describe_categorical(X):\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(X_train[X_train.columns[X_train.dtypes == 'object']].describe().to_html()))\n",
    "describe_categorical(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables of passenger Id, Name, and Ticket all identify the passengers. For now we can drop Name and Ticket because we are using passenger ID as the index variable. Then from the table I know that Sex, Cabin, and Embarked can all be made into dummy variables. I will clean cabin so that just the cabin category (eg: Cabin A) will have a dummy variable. Then I will make dummies for sex and embarked port. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('Name', axis = 1)\n",
    "train = train.drop('Ticket', axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = test.drop('Name', axis = 1)\n",
    "test = test.drop('Ticket', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cabin(x):\n",
    "    try: \n",
    "        return x[0]\n",
    "    except TypeError:\n",
    "        return \"None\"\n",
    "train['Cabin'] = train.Cabin.apply(clean_cabin)\n",
    "\n",
    "test['Cabin'] = test.Cabin.apply(clean_cabin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_variables = ['Sex', 'Cabin', 'Embarked']\n",
    "\n",
    "for variable in categorical_variables:\n",
    "    train[variable].fillna('Missing', inplace = True )\n",
    "    dummies = pd.get_dummies(train[variable], prefix = variable)\n",
    "    train = pd.concat([train, dummies], axis =1)\n",
    "    train.drop([variable], axis = 1, inplace = True)\n",
    "test_categorical_variables =test[['Sex', 'Cabin', 'Embarked']]\n",
    "    \n",
    "for variable in test_categorical_variables:\n",
    "    test[variable].fillna('Missing', inplace = True )\n",
    "    dummies = pd.get_dummies(test[variable], prefix = variable)\n",
    "    test = pd.concat([test, dummies], axis =1)\n",
    "    test.drop([variable], axis = 1, inplace = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_None</th>\n",
       "      <th>Cabin_T</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Missing</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass   Age  SibSp  Parch     Fare  Sex_female  Sex_male  \\\n",
       "PassengerId                                                              \n",
       "1                 3  22.0      1      0   7.2500           0         1   \n",
       "2                 1  38.0      1      0  71.2833           1         0   \n",
       "3                 3  26.0      0      0   7.9250           1         0   \n",
       "4                 1  35.0      1      0  53.1000           1         0   \n",
       "5                 3  35.0      0      0   8.0500           0         1   \n",
       "\n",
       "             Cabin_A  Cabin_B  Cabin_C  Cabin_D  Cabin_E  Cabin_F  Cabin_G  \\\n",
       "PassengerId                                                                  \n",
       "1                  0        0        0        0        0        0        0   \n",
       "2                  0        0        1        0        0        0        0   \n",
       "3                  0        0        0        0        0        0        0   \n",
       "4                  0        0        1        0        0        0        0   \n",
       "5                  0        0        0        0        0        0        0   \n",
       "\n",
       "             Cabin_None  Cabin_T  Embarked_C  Embarked_Missing  Embarked_Q  \\\n",
       "PassengerId                                                                  \n",
       "1                     1        0           0                 0           0   \n",
       "2                     0        0           1                 0           0   \n",
       "3                     1        0           0                 0           0   \n",
       "4                     0        0           0                 0           0   \n",
       "5                     1        0           0                 0           0   \n",
       "\n",
       "             Embarked_S  \n",
       "PassengerId              \n",
       "1                     1  \n",
       "2                     0  \n",
       "3                     1  \n",
       "4                     1  \n",
       "5                     1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at the data to make sure the dummies where created right\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.85      0.83       175\n",
      "          1       0.76      0.69      0.72       120\n",
      "\n",
      "avg / total       0.78      0.79      0.78       295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#now I can resplit my data to make a second hopefully more accurate random forest classifer. \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.33, random_state=42)\n",
    "\n",
    "rf_model2 = RandomForestClassifier(n_estimators = 100, oob_score = True, n_jobs = -1, random_state= 42)\n",
    "rf_model2.fit(X_train, y_train)\n",
    "test_predictions = rf_model2.predict(X_test)\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d569a26400>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcQAAAD8CAYAAADpAdRrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERFACmJERAQA/x+HMsTbNu6t5AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d569a267b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Now I want to look that most important features\n",
    "feature_imp = sorted(list(zip(train.columns, rf_model2.feature_importances_)), key=lambda x: x[1], reverse=True)\n",
    "pd.Series([x[1] for x in feature_imp], index=[x[0] for x in feature_imp]).plot(kind='barh')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can tell from the graph that Fare, Age, Sex, and Pclass are the most important variables so I will do additional feature engineer to those variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fare</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Pclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>32.204208</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.647587</td>\n",
       "      <td>0.352413</td>\n",
       "      <td>2.308642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>49.693429</td>\n",
       "      <td>13.002015</td>\n",
       "      <td>0.477990</td>\n",
       "      <td>0.477990</td>\n",
       "      <td>0.836071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.910400</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.454200</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>512.329200</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Fare         Age    Sex_male  Sex_female      Pclass\n",
       "count  891.000000  891.000000  891.000000  891.000000  891.000000\n",
       "mean    32.204208   29.699118    0.647587    0.352413    2.308642\n",
       "std     49.693429   13.002015    0.477990    0.477990    0.836071\n",
       "min      0.000000    0.420000    0.000000    0.000000    1.000000\n",
       "25%      7.910400   22.000000    0.000000    0.000000    2.000000\n",
       "50%     14.454200   29.699118    1.000000    0.000000    3.000000\n",
       "75%     31.000000   35.000000    1.000000    1.000000    3.000000\n",
       "max    512.329200   80.000000    1.000000    1.000000    3.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['Fare', 'Age', 'Sex_male', 'Sex_female', 'Pclass']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting the age variable into 5 baskets\n",
    "train['age_bin'] = pd.cut(train['Age'].astype(int), 5)\n",
    "test['age_bin'] = pd.cut(test['Age'].astype(int), 5)\n",
    "\n",
    "#splitting the fare variable into 5 baskets\n",
    "train['fare_bin'] = pd.cut(train['Fare'], 4)\n",
    "test['fare_bin'] = pd.cut(test['Fare'], 4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the original variables\n",
    "\n",
    "train = train.drop('Age', axis = 1)\n",
    "test = test.drop('Age', axis =1 )\n",
    "train = train.drop('Fare', axis = 1)\n",
    "test = test.drop('Fare', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a family size variable which is found by adding the sibling and parent column together\n",
    "train['family_size'] = train['SibSp'] + train['Parch'] + 1\n",
    "test['family_size'] = test['SibSp'] + test['Parch'] + 1\n",
    "\n",
    "#making a dummy variable for if the travelor had no family with them\n",
    "train['is_alone'] = train['family_size'].apply(lambda x: 1 if x == 1 else 0)\n",
    "test['is_alone'] = test['family_size'].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "#making a dummy variable for each passenger class\n",
    "pclass = pd.get_dummies(train['Pclass']) \n",
    "pclass2 = pd.get_dummies(test['Pclass'])\n",
    "train = pd.concat([train, pclass], axis = 1)\n",
    "test = pd.concat([test, pclass2], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_bin = pd.get_dummies(train[['age_bin', 'fare_bin']])\n",
    "train = pd.concat([train, age_bin], axis = 1)\n",
    "train = train.drop(['age_bin'], axis = 1)\n",
    "train = train.drop(['fare_bin'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_bin2 = pd.get_dummies(test[['age_bin', 'fare_bin']])\n",
    "test = pd.concat([test, age_bin2], axis = 1)\n",
    "test = test.drop(['age_bin'], axis = 1)\n",
    "test = test.drop(['fare_bin'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I've done more feature engineering, I can try a 3rd model with random forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1 balanced\n",
      "1000 1 None\n",
      "1000 3 balanced\n",
      "1000 3 None\n",
      "1000 5 balanced\n",
      "1000 5 None\n",
      "1000 10 balanced\n",
      "1000 10 None\n",
      "2500 1 balanced\n",
      "2500 1 None\n",
      "2500 3 balanced\n",
      "2500 3 None\n",
      "2500 5 balanced\n",
      "2500 5 None\n",
      "2500 10 balanced\n",
      "2500 10 None\n",
      "5000 1 balanced\n",
      "5000 1 None\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.33, random_state=42) \n",
    "\n",
    "n_estimators = [1000, 2500, 5000]\n",
    "max_depth = [1, 3, 5, 10]\n",
    "class_weights = ['balanced', None]\n",
    "best_f1 = 0\n",
    "\n",
    "for est in n_estimators:\n",
    "    for depth in max_depth:\n",
    "        for wgt in class_weights:\n",
    "            print(est, depth, wgt)\n",
    "            clf = RandomForestClassifier(n_estimators=est, max_depth=depth, oob_score=True, class_weight=wgt)\n",
    "            clf.fit(X_train,y_train)\n",
    "            f1 = f1_score(y_train, np.argmax(clf.oob_decision_function_ , 1))\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_params = (est, depth, wgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "rf_model3 = (n_estimators=best_params[0], max_depth=best_params[1], class_weight=best_params[2])\n",
    "rf_model3.fit(X_train, y_train)\n",
    "test_predictions = rf_model3.predict(X_test)\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  K Nearest Neighbors Classification \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have a good predition using Random Forest I will use the K-Nearest Neighbors Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier()\n",
    "gridsearch = GridSearchCV(clf, {\"n_neighbors\": [1, 3, 5, 7,8, 9, 10, 11], \"weights\": ['uniform', 'distance'], \n",
    "                                'p': [1, 2, 3]}, scoring='f1')\n",
    "gridsearch.fit(X_train, y_train)\n",
    "\n",
    "#evaluate model\n",
    "\n",
    "print(\"Best Params: {}\".format(gridsearch.best_params_))\n",
    "y_pred_train = gridsearch.predict(X_train)\n",
    "print(\"Train F1: {}\".format(f1_score(y_train, y_pred_train)))\n",
    "print(\"Test Classification Report:\")\n",
    "y_pred_test = gridsearch.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print(\"Train Accuracy: {}\\tTest accuracy: {}\".format(accuracy_score(y_train, y_pred_train), accuracy_score(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K Nearest Neighbors Classifier does predict as well as the random forest classifier. The f1 score of k nearest neighbors is lower than the f1 score of rf_model3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import  GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC()\n",
    "svm = GridSearchCV(clf, {\"C\": [0.2, 0.5, 0.7], \"kernel\": ['linear', 'poly', 'rbf'], \n",
    "\n",
    "                                'degree': [1, 2, 3], 'gamma': [1, 5, 11]}, scoring='accuracy')\n",
    "svm.fit(X_train, y_train)\n",
    "#evaluate model\n",
    "\n",
    "print(\"Best Params: {}\".format(gridsearch.best_params_))\n",
    "print(\"Test Accuracy: {}\".format(accuracy_score(y_test, gridsearch.predict(X_test))))\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After comparing Random Forest, K Nearest Neighbors, and SVM classifiers, I decided that random forest gave the best predictions. This is because the f1 - score was highest for random forest. While the random forest prediction isn't perfect it gives an accurate prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitting to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.fillna(train.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Embarked_Missing'] = 0\n",
    "test['Cabin_T'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rf_model3.predict(test)\n",
    "\n",
    "submission = pd.DataFrame({'PassengerId':test.index,'Survived':pred})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
